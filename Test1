import subprocess
import json
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import RLock, Lock
import logging
import multiprocessing
import time
import shlex
import shutil

logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)

class GitRepositoryManager:
    def __init__(self, log_level=logging.INFO, timeout=120, retries=3):
        self.repo_locks = {}
        self.repo_lock_global = Lock()
        self.timeout = timeout
        self.retries = retries
        log.setLevel(log_level)

    def run_command(self, cmd, cwd=None):
        attempt, backoff = 0, 1
        while attempt < self.retries:
            try:
                log.debug(f"Running command: {cmd} in {cwd}")
                process = subprocess.run(shlex.split(cmd), check=True, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=self.timeout)
                return process.stdout.decode().strip()
            except subprocess.CalledProcessError as e:
                error_message = e.stderr.decode().strip()
                log.error(f"Command failed: {error_message}")
                if "fatal" in error_message.lower():
                    raise RuntimeError(f"Fatal error during execution: {cmd}")
            except subprocess.TimeoutExpired:
                log.error(f"Command timed out: {cmd} in {cwd}")
            attempt += 1
            if attempt >= self.retries:
                raise RuntimeError(f"Command failed after {self.retries} attempts: {cmd}")
            time.sleep(backoff)
            backoff *= 2

    def get_current_branch(self, repo_path):
        try:
            return self.run_command("git symbolic-ref --short HEAD", cwd=repo_path)
        except RuntimeError:
            return self.run_command("git rev-parse --short HEAD", cwd=repo_path)

    def is_up_to_date(self, repo_path):
        try:
            return self.run_command("git rev-parse @", cwd=repo_path) == self.run_command("git rev-parse @{u}", cwd=repo_path)
        except subprocess.CalledProcessError as e:
            log.warning(e.stderr.decode().strip())
            return False

    def clone_repository(self, repo_url, repo_name, branch, depth=1):
        if not os.path.exists(repo_name):
            log.info(f"Cloning {repo_url} (branch: {branch})")
            depth_arg = f"--depth {depth}" if depth else ""
            try:
                self.run_command(f"git clone {depth_arg} --branch {branch} --single-branch {repo_url}")
            except RuntimeError:
                shutil.rmtree(repo_name, ignore_errors=True)
                raise
        else:
            log.info(f"Repository {repo_name} already exists. Skipping clone.")

    def checkout_and_pull(self, repo_path, branch):
        with self._get_repo_lock(repo_path):
            if self.get_current_branch(repo_path) != branch:
                self.run_command(f"git checkout {branch}", cwd=repo_path)
            if not self.is_up_to_date(repo_path):
                self.run_command(f"git pull origin {branch}", cwd=repo_path)

    def initialize_submodules(self, repo_path):
        if not os.path.exists(os.path.join(repo_path, '.gitmodules')):
            return False
        self.run_command("git submodule update --init --recursive --jobs 4", cwd=repo_path)
        return True

    def update_submodule(self, repo_path, submodule, branch="main"):
        submodule_path = os.path.join(repo_path, submodule.split()[1])
        lock_file = os.path.join(repo_path, f".git/modules/{submodule_path}/index.lock")
        if os.path.exists(lock_file):
            os.remove(lock_file)
        if not os.path.isdir(os.path.join(submodule_path, ".git")):
            shutil.rmtree(submodule_path, ignore_errors=True)
            self.run_command("git submodule update --init --recursive --force", cwd=repo_path)
        with self._get_repo_lock(submodule_path):
            if self.run_command(f"git ls-remote --heads origin {branch}", cwd=submodule_path):
                self.run_command(f"git checkout {branch}", cwd=submodule_path)
            if not self.is_up_to_date(submodule_path):
                self.run_command(f"git pull origin {branch}", cwd=submodule_path)

    def process_repository(self, repo):
        repo_url = repo['repo_url']
        branch = repo['branch']
        repo_name = repo_url.split('/')[-1].replace('.git', '')
        self.clone_repository(repo_url, repo_name, branch)
        self.checkout_and_pull(repo_name, branch)
        self.initialize_submodules(repo_name)

    def process_all_repositories(self, json_file):
        with open(json_file) as f:
            repositories = json.load(f)['repositories']
        max_workers = min(32, multiprocessing.cpu_count() + 4)
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(self.process_repository, repo) for repo in repositories]
            for future in as_completed(futures):
                future.result()

    def _get_repo_lock(self, repo_path):
        with self.repo_lock_global:
            if repo_path not in self.repo_locks:
                self.repo_locks[repo_path] = RLock()
        return self.repo_locks[repo_path]


if __name__ == "__main__":
    manager = GitRepositoryManager(log_level=logging.INFO, timeout=120, retries=3)
    manager.process_all_repositories('repositories.json')
